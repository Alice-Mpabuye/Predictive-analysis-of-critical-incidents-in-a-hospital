{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d84ee26",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "The objective of this notebook is to clean and validate the datasets used in this project\n",
    "(primary, study, and validation cohorts) in order to ensure data consistency, integrity,\n",
    "and suitability for downstream machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a5cc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"../data\")\n",
    "\n",
    "primary = pd.read_csv(DATA_PATH/\"primary_cohort.csv\")\n",
    "study = pd.read_csv(DATA_PATH/\"study_cohort.csv\")\n",
    "validation = pd.read_csv(DATA_PATH/\"validation_cohort.csv\")\n",
    "\n",
    "cohorts = {\n",
    "    \"primary\": primary,\n",
    "    \"study\": study,\n",
    "    \"validation\": validation\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b4889",
   "metadata": {},
   "source": [
    "## Verify data consistency (datasets)\n",
    "\n",
    "Three cohorts are used in this project:\n",
    "- Primary cohort\n",
    "- Study cohort\n",
    "- Validation cohort\n",
    "\n",
    "All cohorts share the same schema and are cleaned using identical rules to ensure\n",
    "consistency across the data pipeline.\n",
    "\n",
    "### Age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56096e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    110204.000000\n",
       "mean         62.735255\n",
       "std          24.126806\n",
       "min           0.000000\n",
       "25%          51.000000\n",
       "50%          68.000000\n",
       "75%          81.000000\n",
       "max         100.000000\n",
       "Name: age_years, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary[\"age_years\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "743c35f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(primary[\"age_years\"] < 0).sum()\n",
    "(primary[\"age_years\"] > 120).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9abab1",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29ade285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex_0male_1female\n",
       "0    57973\n",
       "1    52231\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary[\"sex_0male_1female\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86a5eea",
   "metadata": {},
   "source": [
    "### Hopital Outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f5c652e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hospital_outcome_1alive_0dead\n",
       "1    102099\n",
       "0      8105\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary[\"hospital_outcome_1alive_0dead\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff4696",
   "metadata": {},
   "source": [
    "## Verify the structure\n",
    "Pre-cleaning data validation\n",
    "\n",
    "Before applying any cleaning operations, basic validation checks were performed to\n",
    "identify potential data quality issues, including invalid values, missing values,\n",
    "and duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52eae266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "primary.columns.equals(study.columns)\n",
    "primary.columns.equals(validation.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633c35cb",
   "metadata": {},
   "source": [
    "## Intra-cohort cleaning\n",
    "### Minimal clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdf5fee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIMARY COHORT ---\n",
      "(110204, 4)\n",
      "age_years                        0\n",
      "sex_0male_1female                0\n",
      "episode_number                   0\n",
      "hospital_outcome_1alive_0dead    0\n",
      "dtype: int64\n",
      "Duplicated rows: 108693\n",
      "\n",
      "--- STUDY COHORT ---\n",
      "(19051, 4)\n",
      "age_years                        0\n",
      "sex_0male_1female                0\n",
      "episode_number                   0\n",
      "hospital_outcome_1alive_0dead    0\n",
      "dtype: int64\n",
      "Duplicated rows: 17861\n",
      "\n",
      "--- VALIDATION COHORT ---\n",
      "(137, 4)\n",
      "age_years                        0\n",
      "sex_0male_1female                0\n",
      "episode_number                   0\n",
      "hospital_outcome_1alive_0dead    0\n",
      "dtype: int64\n",
      "Duplicated rows: 33\n"
     ]
    }
   ],
   "source": [
    "for name, df in cohorts.items():\n",
    "    print(f\"\\n--- {name.upper()} COHORT ---\")\n",
    "    print(df.shape)\n",
    "    print(df.isna().sum())\n",
    "    print(\"Duplicated rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0bd52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cohort(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    df = df[(df[\"age_years\"] >= 0) & (df[\"age_years\"] <= 120)]\n",
    "\n",
    "    df = df[df[\"sex_0male_1female\"].isin([0, 1])]\n",
    "    df = df[df[\"hospital_outcome_1alive_0dead\"].isin([0, 1])]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f666d",
   "metadata": {},
   "source": [
    "## Cleaning rules\n",
    "\n",
    "The following cleaning rules were applied uniformly across all cohorts:\n",
    "\n",
    "- Removal of duplicated rows\n",
    "- Removal of records with invalid ages (age < 0 or age > 120)\n",
    "- Enforcement of binary encoding for sex (0 = male, 1 = female)\n",
    "- Enforcement of binary encoding for hospital outcome (0 = deceased, 1 = alive)\n",
    "\n",
    "These rules are based on basic data validity constraints and do not rely on the target\n",
    "distribution or any modeling assumptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4105a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cohorts:\n",
    "    cohorts[name] = clean_cohort(cohorts[name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452ce4a",
   "metadata": {},
   "source": [
    "## Cleaning impact summary\n",
    "\n",
    "The cleaning process resulted in the removal of a small number of records that violated\n",
    "basic validity constraints. The impact of the cleaning process was monitored for each\n",
    "cohort to ensure that no unintended data loss occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0aa39",
   "metadata": {},
   "source": [
    "## Post-cleaning validation\n",
    "\n",
    "After cleaning, all datasets were re-validated to confirm:\n",
    "- absence of duplicated rows\n",
    "- valid value ranges for all variables\n",
    "- consistent data types\n",
    "- absence of missing values\n",
    "\n",
    "The cleaned datasets are considered ready for feature engineering and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a1e0f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- PRIMARY AFTER CLEANING ---\n",
      "(1511, 4)\n",
      "Duplicated rows: 0\n",
      "\n",
      "--- STUDY AFTER CLEANING ---\n",
      "(1190, 4)\n",
      "Duplicated rows: 0\n",
      "\n",
      "--- VALIDATION AFTER CLEANING ---\n",
      "(104, 4)\n",
      "Duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "for name, df in cohorts.items():\n",
    "    print(f\"\\n--- {name.upper()} AFTER CLEANING ---\")\n",
    "    print(df.shape)\n",
    "    print(\"Duplicated rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd63167",
   "metadata": {},
   "source": [
    "## Create a clean, final CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8af47462",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohorts[\"primary\"].to_csv(DATA_PATH/\"primary_cohort_clean.csv\", index=False)\n",
    "cohorts[\"study\"].to_csv(DATA_PATH/\"study_cohort_clean.csv\", index=False)\n",
    "cohorts[\"validation\"].to_csv(DATA_PATH/\"validation_cohort_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a04664",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This data cleaning step ensures that all cohorts are structurally consistent and free\n",
    "from basic data quality issues. The cleaned datasets are saved as separate CSV files\n",
    "and will be used as input for the next phases of the project.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
